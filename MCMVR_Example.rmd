---
title: "MCMVR Example"
author: "Aaron J. Molstad (amolstad@ufl.edu)"
date: "7/18/2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
library(Rcpp)
library(RcppArmadillo)
source("~/Documents/GitHub/MCMVR/R/MCMVR.R")
sourceCpp("~/Documents/GitHub/MCMVR/src/MCnegloglikCpp.cpp")
```


In this document, we provide a short tutorial on how to use the $\texttt{MCMVR}$ R package. We download this package from GitHub. 
```{r githubDL, eval=FALSE}
install.packages("devtools")
library(devtools)
devtools::install_github("ajmolstad/MCMVR")
library(MCMVR)
```

First, we generate data from the "errors-in-variables" data generating model described in Section 3.1 of the article. 
```{r generate data, tidy=TRUE}
set.seed(1)
p <- 50
q <- 10
n <- 100

beta <- matrix(rnorm(p*q)*sample(c(0,1), p*q, prob = c(.9, .1), replace=TRUE), nrow=p, ncol=q)

Z <- matrix(rnorm(n*p), nrow=n, ncol=p)
Y <- tcrossprod(Z, t(beta)) + matrix(rnorm(n*q, sd=1), nrow=n)
X <- Z + matrix(rnorm(n*p, sd=sqrt(0.5)), nrow=n)

Znew <- matrix(rnorm(n*p), nrow=n, ncol=p)
Xnew <- Znew + matrix(rnorm(n*p, sd=sqrt(0.5)), nrow=n)
Ynew <- tcrossprod(Znew, t(beta)) + matrix(rnorm(n*q, sd=1), nrow=n)
```
We fit the model using the cross-validation function. There are a number of key arguments: the first is $\texttt{tau.vec}$, where a user must specify a vector of candidate tuning parameters $\tau$ over which to fit the model: 
$$ \arg \min_{\beta} {\rm tr}\left\{n^{-1}(Y - X\beta) (\beta'\beta + \tau I_q)^{-1}(Y - X\beta)' \right\} + \frac{\lambda}{\tau}{\rm Pen}(\beta).$$
Another important argument is $\texttt{nfolds}$. If set to NULL, cross-validation is not performed, the model is fit to the complete data without cross-validation. 
Finally, a user must also decide which penalty to use. The current options are $\texttt{penalty="L1"}$ and $\texttt{penalty="NN"}$ which set ${\rm Pen}(\beta) = \sum_{j,k}|\beta_{j,k}|$ and ${\rm Pen}(\beta) = \sum_{j=1}^{\min (p,q)} \varphi_j(\beta)$, respectively, where $\varphi_j(\beta)$ is the $j$th largest singular value of $\beta$. Note that one only needs to input the number of candidate $\lambda$, $\texttt{nlambda}$, and the ratio of max to min lambda $\texttt{delta}$. 
```{r fit model, tidy=TRUE}
# ---------------------------------------------------
# Perform 5-fold CV for a grid of tuning parameters 
# ---------------------------------------------------
tau.vec <- 10^seq(3, 0, by=-.5)
fit <- MCMVR.cv(X = X, Y = Y, tau.vec = tau.vec, nlambda = 50, nfolds = 5, 
  delta = .01, tol = 1e-8, quiet= TRUE, inner.quiet= TRUE, penalty="L1")
str(fit)
# ---------------------------------------------------
# visualize CV error
# ---------------------------------------------------
library(lattice)
levelplot(apply(fit$err.pred, c(1,2), mean), col.regions=grey(100:0/100), xlab=expression(lambda), ylab=expression(tau), aspect="fill")

# ---------------------------------------------------
# get coefs from model which minimized CV error
# ---------------------------------------------------
betas <- MCMVR.coef(fit)$beta

par(mfrow=c(1,2))
image(betas!=0, col=grey(100:0/100), main=paste("Nonzero entries of estimate"))
image(beta!=0, col=grey(100:0/100), main=paste("Nonzero entries of truth"))

# -------------------------------------------------
# make predictions for Xnew
# ------------------------------------------------
preds <- MCMVR.predict(Xnew, fit)

par(mfrow=c(1,2))
plot(preds$preds[,1], Ynew[,1], pch=20, main="Response 1", ylab="Our prediction", xlab="True response")
abline(0,1, lty=2)
plot(preds$preds[,2], Ynew[,2], pch=20, main="Response 2", ylab="Our prediction", xlab="True response")
abline(0,1, lty=2)

# ---------------------------------------------------
# get coefs from model with seperate tuning parameter
# ---------------------------------------------------
betas <- MCMVR.coef(fit, tau = fit$tau.vec[1], lambda=fit$lambda.vec[12])$beta

par(mfrow=c(1,2))
image(betas!=0, col=grey(100:0/100), main=paste("Nonzero entries of estimate"))
image(beta!=0, col=grey(100:0/100), main=paste("Nonzero entries of truth"))
```


We now also fit the model for the nuclear norm penalized version. Note that it is sometimes useful to relax the convergence tolerance for this version. We also turn off the $\texttt{quiet}$ option. When $\texttt{penalty = "NN"}$, this option prints the value of the nuclear norm evaluated at the estimate; when $\texttt{penalty = "L1"}$, this option prints the number of nonzero entries in the estimate of $\beta_*$. Note that $\texttt{inner.quiet = FALSE}$ should only be used for determining an appropriate value of $\texttt{tol}$. 

```{r generate RR data, tidy=TRUE}
# ---------------------------------------------------
# Perform 5-fold CV for a grid of tuning parameters 
# ---------------------------------------------------
tau.vec <- 10^seq(3, 0, by=-.5)
fit <- MCMVR.cv(X = X, Y = Y, tau.vec = tau.vec, nlambda = 20, nfolds = 5, 
  delta = .01, tol = 1e-10, quiet = FALSE, inner.quiet= TRUE, penalty="NN")
str(fit)
levelplot(apply(fit$err.pred, c(1,2), mean), col.regions=grey(100:0/100), xlab=expression(lambda), ylab=expression(tau), aspect="fill")

```